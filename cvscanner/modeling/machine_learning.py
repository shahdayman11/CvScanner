# -*- coding: utf-8 -*-
"""machine_learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X0uNTEjIPN_Krjq7nwwC6RG5lfMrra4e
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from sklearn.svm import LinearSVC
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import normalize
import streamlit as st#--

try:
    df
except NameError:
    #df = pd.read_csv("/content/cleanedV2.csv")
    df = pd.read_csv("data/processed/cleanedV2.csv")


# Ensure Skills is a list
def parse_skills(x):
    if isinstance(x, list):
        return x
    if pd.isna(x):
        return []
    try:
        parsed = ast.literal_eval(x)
        if isinstance(parsed, list):

            return [str(s).strip().lower() for s in parsed if str(s).strip()]
        return []
    except Exception:

        if isinstance(x, str):
            return [t.strip().lower() for t in x.replace("[","").replace("]","").split(",") if t.strip()]
        return []

df["Skills_List"] = df["Skills"].apply(parse_skills)


df["text"] = df["Cleaned_Resume"].fillna("") + " " + df["Skills_List"].apply(lambda lst: " ".join(lst))


y = df["Category"].astype(str).values
X_text = df["text"].values

X_train, X_test, y_train, y_test = train_test_split(
    X_text, y, test_size=0.2, random_state=42, stratify=y
)

clf = make_pipeline(
    TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.9, sublinear_tf=True),
    LinearSVC()
)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

acc = accuracy_score(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average="macro")
report = classification_report(y_test, y_pred, output_dict=False)





metrics_df = pd.DataFrame({
    "Metric": ["Accuracy", "F1 (macro)"],
    "Score": [acc, f1_macro]
})
st.dataframe(metrics_df)#--
st.text(report)#--


student_skills = "python sql machine learning pandas scikit-learn"
predicted_category = clf.predict([student_skills])[0]
#print("Predicted Career Path:", predicted_category)
st.write("**Predicted Career Path:**", predicted_category)

vec = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.9, sublinear_tf=True)
X_all = vec.fit_transform(df["text"].values)

k_candidates = list(range(3, min(12, len(df)//6 + 3)))
sil_scores = []
for k in k_candidates:
    km = KMeans(n_clusters=k, random_state=42, n_init=10)
    labs = km.fit_predict(X_all)
    #==
    if len(set(labs)) > 1:  # only calculate if at least 2 clusters
    sil = float(silhouette_score(X_all, labs, metric='cosine'))
else:
    sil = 0.0  # fallback if only one cluster
    sil_scores.append(sil)

best_k = int(k_candidates[int(np.argmax(sil_scores))])




kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=25)
cluster_labels = kmeans.fit_predict(X_all)




def top_terms_per_cluster(vec, km, n_terms=13):
    terms = vec.get_feature_names_out()
    order_centroids = km.cluster_centers_.argsort()[:, ::-1]
    for i in range(km.n_clusters):
       # print(f"\nCluster {i}:")
        st.write(f"### Cluster {i}")
        for ind in order_centroids[i, :n_terms]:
            #print("  ", terms[ind])
             st.write(" -", terms[ind])

top_terms_per_cluster(vec, kmeans, n_terms=13)

X_norm = normalize(X_all, norm="l2", axis=1)


nn = NearestNeighbors(metric="cosine", n_neighbors=10)
nn.fit(X_norm)

example_skills = "python, sql, machine learning, pandas, scikit-learn"


vx = vec.transform([example_skills])
vx = normalize(vx, norm="l2", axis=1)


distances, indices = nn.kneighbors(vx, n_neighbors=8)

similarities = 1 - distances.flatten()


recommended_cats = df.iloc[indices.flatten()]["Category"].values


top_categories = (
    pd.Series(recommended_cats)
    .value_counts()
    .head(5)
    .reset_index()
)
top_categories.columns = ["Recommended Category", "Votes"]


#print("Example skills:", example_skills)
st.write("**Example skills:**", example_skills)
#print("\nTop recommended categories based on similarity:")
st.write("### Top recommended categories based on similarity")
#print(top_categories)
st.dataframe(top_categories)


summary = {
    "best_k": best_k,
    "example_input": example_skills,
    "recommendations": top_categories.to_dict(orient="records"),
}

st.json(summary)
